1. Какое качество получилось у логистической регрессии над всеми исходными
признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы
можете объяснить эту разницу? Быстрее ли работает логистическая регрессия
по сравнению с градиентным бустингом?

В лучшем случае качество получилось 0.653792271116. Это лучше, чем при 
использовании градиентного бустинга. Разницу, вероятно, можно объяснить
большим количеством пропусков в данных. К тому же, вероятно, что можно
достичь лучших результатов для градиентного бустинга при использовании
значительно большего числа деревьев. Логистическая регрессия работает
значительно быстрее.

2. Как влияет на качество логистической регрессии удаление категориальных
признаков (укажите новое значение метрики качества)? Чем вы можете объяснить
это изменение?

Лучшее полученное значение на выборке без категориальных признаков -
0.65396795402, что незначительно лучше, чем при использовании исходной
выборки. Предположу, что это связано с тем, что каждый игрок выбирает
наиболее изученных им героев, из-за чего это практически не сказывается
на результатах матча. К тому же игроки в матчах подбираются приблизительно
равные по уровню игры.

3. Сколько различных идентификаторов героев существует в данной игре?

В тестовой выборке 108 различных идентификаторов персонажей. При этом
максимальный идентификатор - 112. На официальном сайте указаны 113
игровых персонажей на данный момент. Учитывая, что данные были собраны
в 2015 году, предположу, что в то время было доступно 112 героев,
некоторые из которых не были выбраны в ходе матчей из тестовых данных.

4. Какое получилось качество при добавлении "мешка слов" по героям?
Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете
это объяснить?

После добавления мешка слов качество в лучшем случае достигло значения
0.653813650883, что немного хуже, чем при удалении категориальных
признаков, но чуть лучше, чем при использовании исходной выборки.
Думаю, это связано с тем, что выбор героев не влияет на результат,
и наличие категориальных признаков в том или ином виде лишь мешает
алгоритму обучаться.

5. Какое минимальное и максимальное значение прогноза на тестовой
выборке получилось у лучшего из алгоритмов?

0.00772300711639 и 0.985751676446 соответсвенно.

P.S. По результатам отправки лучшей модели(с удалением категориальных признаков)
для проверки на Kaggle, она получила оценку 0.72306
